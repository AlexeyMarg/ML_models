{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], dtype=torch.float16)\n",
      "tensor([1.], dtype=torch.float16)\n",
      "tensor([2.], dtype=torch.float16)\n",
      "tensor([3.], dtype=torch.float16)\n",
      "tensor([4.], dtype=torch.float16)\n",
      "tensor([5.], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "t = torch.arange(6, dtype=torch.float16)\n",
    "data_loader = DataLoader(t)\n",
    "for item in data_loader:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1: tensor([0., 1., 2.], dtype=torch.float16)\n",
      "batch 2: tensor([3., 4., 5.], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(t, batch_size=3, drop_last=False)\n",
    "for i, batch in enumerate(data_loader, 1):\n",
    "    print(f'batch {i}:', batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "t_x = torch.rand([4, 3], dtype=torch.float32)\n",
    "t_y = torch.arange(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDatasset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x:  tensor([0.7576, 0.2793, 0.4031])  y:  tensor(0)\n",
      " x:  tensor([0.7347, 0.0293, 0.7999])  y:  tensor(1)\n",
      " x:  tensor([0.3971, 0.7544, 0.5695])  y:  tensor(2)\n",
      " x:  tensor([0.4388, 0.6387, 0.5247])  y:  tensor(3)\n"
     ]
    }
   ],
   "source": [
    "my_dataset = myDatasset(t_x, t_y)\n",
    "for example in my_dataset:\n",
    "    print(' x: ', example[0], ' y: ', example[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "batch 1: x: tensor([[0.3971, 0.7544, 0.5695],\n",
      "        [0.7576, 0.2793, 0.4031]]) \n",
      "         y: tensor([2, 0])\n",
      "batch 2: x: tensor([[0.7347, 0.0293, 0.7999],\n",
      "        [0.4388, 0.6387, 0.5247]]) \n",
      "         y: tensor([1, 3])\n",
      "epoch 2\n",
      "batch 1: x: tensor([[0.7576, 0.2793, 0.4031],\n",
      "        [0.3971, 0.7544, 0.5695]]) \n",
      "         y: tensor([0, 2])\n",
      "batch 2: x: tensor([[0.7347, 0.0293, 0.7999],\n",
      "        [0.4388, 0.6387, 0.5247]]) \n",
      "         y: tensor([1, 3])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "data_loader = DataLoader(dataset=my_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "for epoch in range(2):\n",
    "    print(f'epoch {epoch+1}')\n",
    "    for i, batch in enumerate(data_loader, 1):\n",
    "        print(f'batch {i}:', 'x:', batch[0], \n",
    "              '\\n         y:', batch[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataset from files on your local storage disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "imgdir_path = pathlib.Path('cat_dog_images')\n",
    "\n",
    "file_list = sorted([str(path) for path in imgdir_path.glob('*.jpg')])\n",
    "\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "for i, file in enumerate(file_list):\n",
    "    img = Image.open(file)\n",
    "    print('Image shape: ', np.array(img).shape)\n",
    "    ax = fig.add_subplot(2, 3, i+1)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(os.path.basename(file), size=15)\n",
    "    \n",
    "#plt.savefig('figures/12_03.pdf')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1 if 'dog' in os.path.basename(file) else 0\n",
    "          for file in file_list]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, file_list, labels):\n",
    "        self.file_list = file_list\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file = self.file_list[index]      \n",
    "        label = self.labels[index]\n",
    "        return file, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "image_dataset = ImageDataset(file_list, labels)\n",
    "for file, label in image_dataset:\n",
    "    print(file, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, file_list, labels, transform=None):\n",
    "        self.file_list = file_list\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.file_list[index])        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[index]\n",
    "        return img, label\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "img_height, img_width = 80, 120\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "])\n",
    "    \n",
    "image_dataset = ImageDataset(file_list, labels, transform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
