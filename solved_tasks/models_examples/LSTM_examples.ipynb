{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import Sequential, Model\n",
    "from keras.layers import LSTM, Dense, Bidirectional, Input, TimeDistributed, RepeatVector\n",
    "from keras.utils import get_file\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>Tpot (K)</th>\n",
       "      <th>Tdew (degC)</th>\n",
       "      <th>rh (%)</th>\n",
       "      <th>VPmax (mbar)</th>\n",
       "      <th>VPact (mbar)</th>\n",
       "      <th>VPdef (mbar)</th>\n",
       "      <th>sh (g/kg)</th>\n",
       "      <th>H2OC (mmol/mol)</th>\n",
       "      <th>rho (g/m**3)</th>\n",
       "      <th>wv (m/s)</th>\n",
       "      <th>max. wv (m/s)</th>\n",
       "      <th>wd (deg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>996.50</td>\n",
       "      <td>-8.05</td>\n",
       "      <td>265.38</td>\n",
       "      <td>-8.78</td>\n",
       "      <td>94.4</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.96</td>\n",
       "      <td>3.15</td>\n",
       "      <td>1307.86</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.63</td>\n",
       "      <td>192.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>996.62</td>\n",
       "      <td>-8.88</td>\n",
       "      <td>264.54</td>\n",
       "      <td>-9.77</td>\n",
       "      <td>93.2</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.91</td>\n",
       "      <td>1312.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.63</td>\n",
       "      <td>190.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>996.84</td>\n",
       "      <td>-8.81</td>\n",
       "      <td>264.59</td>\n",
       "      <td>-9.66</td>\n",
       "      <td>93.5</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.94</td>\n",
       "      <td>1312.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.63</td>\n",
       "      <td>167.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>996.99</td>\n",
       "      <td>-9.05</td>\n",
       "      <td>264.34</td>\n",
       "      <td>-10.02</td>\n",
       "      <td>92.6</td>\n",
       "      <td>3.07</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1313.61</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.38</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>997.46</td>\n",
       "      <td>-9.63</td>\n",
       "      <td>263.72</td>\n",
       "      <td>-10.65</td>\n",
       "      <td>92.2</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2.71</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.69</td>\n",
       "      <td>2.71</td>\n",
       "      <td>1317.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.88</td>\n",
       "      <td>157.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    p (mbar)  T (degC)  Tpot (K)  Tdew (degC)  rh (%)  VPmax (mbar)  \\\n",
       "5     996.50     -8.05    265.38        -8.78    94.4          3.33   \n",
       "11    996.62     -8.88    264.54        -9.77    93.2          3.12   \n",
       "17    996.84     -8.81    264.59        -9.66    93.5          3.13   \n",
       "23    996.99     -9.05    264.34       -10.02    92.6          3.07   \n",
       "29    997.46     -9.63    263.72       -10.65    92.2          2.94   \n",
       "\n",
       "    VPact (mbar)  VPdef (mbar)  sh (g/kg)  H2OC (mmol/mol)  rho (g/m**3)  \\\n",
       "5           3.14          0.19       1.96             3.15       1307.86   \n",
       "11          2.90          0.21       1.81             2.91       1312.25   \n",
       "17          2.93          0.20       1.83             2.94       1312.18   \n",
       "23          2.85          0.23       1.78             2.85       1313.61   \n",
       "29          2.71          0.23       1.69             2.71       1317.19   \n",
       "\n",
       "    wv (m/s)  max. wv (m/s)  wd (deg)  \n",
       "5       0.21           0.63     192.7  \n",
       "11      0.25           0.63     190.3  \n",
       "17      0.18           0.63     167.2  \n",
       "23      0.10           0.38     240.0  \n",
       "29      0.40           0.88     157.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_path = get_file(\n",
    "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
    "    fname='jena_climate_2009_2016.csv.zip',\n",
    "    extract=True)\n",
    "csv_path, _ = os.path.splitext(zip_path)\n",
    "df = pd.read_csv(csv_path)\n",
    "df = df[5::6]\n",
    "date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_data = np.array(df['T (degC)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(0, len(sequence)- n_steps):\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\tX = np.array(X)\n",
    "\ty = np.array(y)\n",
    "\tX = X.reshape(X.shape[0], n_steps, 1)\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70088, 3, 1), (70088,))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = split_sequence(temperature_data, 3)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single step LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(50, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2191/2191 [==============================] - 6s 2ms/step - loss: 3.3302\n",
      "Epoch 2/10\n",
      "2191/2191 [==============================] - 5s 2ms/step - loss: 0.6940\n",
      "Epoch 3/10\n",
      "2191/2191 [==============================] - 4s 2ms/step - loss: 0.6908\n",
      "Epoch 4/10\n",
      "2191/2191 [==============================] - 4s 2ms/step - loss: 0.6820\n",
      "Epoch 5/10\n",
      "2191/2191 [==============================] - 4s 2ms/step - loss: 0.6792\n",
      "Epoch 6/10\n",
      "2191/2191 [==============================] - 4s 2ms/step - loss: 0.6722\n",
      "Epoch 7/10\n",
      "2191/2191 [==============================] - 4s 2ms/step - loss: 0.6694\n",
      "Epoch 8/10\n",
      "2191/2191 [==============================] - 4s 2ms/step - loss: 0.6658\n",
      "Epoch 9/10\n",
      "2191/2191 [==============================] - 4s 2ms/step - loss: 0.6616\n",
      "Epoch 10/10\n",
      "2191/2191 [==============================] - 4s 2ms/step - loss: 0.6590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f1d90c6d10>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi step LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_predictions = 2\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu'),\n",
    "    Dense(num_predictions)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', return_sequences=True),\n",
    "    LSTM(50, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Bidirectional(LSTM(units=50)),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2191/2191 [==============================] - 9s 2ms/step - loss: 5.3054\n",
      "Epoch 2/5\n",
      "2191/2191 [==============================] - 5s 2ms/step - loss: 0.7130\n",
      "Epoch 3/5\n",
      "2191/2191 [==============================] - 5s 2ms/step - loss: 0.6914\n",
      "Epoch 4/5\n",
      "2191/2191 [==============================] - 5s 2ms/step - loss: 0.6766\n",
      "Epoch 5/5\n",
      "2191/2191 [==============================] - 5s 2ms/step - loss: 0.6742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f1d12b6050>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Sequence to sequence (encoder decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the \n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
