{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a76d91dc",
   "metadata": {},
   "source": [
    "# U-Net for image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59c24dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77ca4b8",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0636e1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_class, in_channels=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder1 = self._block(in_channels, 64)\n",
    "        self.encoder2 = self._block(64, 128)\n",
    "        self.encoder3 = self._block(128, 256)\n",
    "        self.encoder4 = self._block(256, 512)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = self._block(512, 1024)\n",
    "        \n",
    "        # Decoder\n",
    "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.decoder4 = self._block(1024, 512) \n",
    "        \n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.decoder3 = self._block(512, 256)\n",
    "        \n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder2 = self._block(256, 128)\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder1 = self._block(128, 64)\n",
    "        \n",
    "        # Output\n",
    "        self.conv_out = nn.Conv2d(64, n_class, kernel_size=1)\n",
    "        \n",
    "    def _block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool(enc1))\n",
    "        enc3 = self.encoder3(self.pool(enc2))\n",
    "        enc4 = self.encoder4(self.pool(enc3))\n",
    "        \n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(self.pool(enc4))\n",
    "        \n",
    "        # Decoder\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat([dec4, enc4], dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        \n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat([dec3, enc3], dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        \n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat([dec2, enc2], dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        \n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat([dec1, enc1], dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        \n",
    "        return self.conv_out(dec1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265ae0f",
   "metadata": {},
   "source": [
    "## Synthetic dataset for simple testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39afa3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesDataset(Dataset):    \n",
    "    def __init__(self, num_samples=500, img_size=128):\n",
    "        self.num_samples = num_samples\n",
    "        self.img_size = img_size\n",
    "        self.shapes = ['circle', 'square', 'triangle']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # empy image\n",
    "        img = np.zeros((self.img_size, self.img_size, 3), dtype=np.uint8)\n",
    "        mask = np.zeros((self.img_size, self.img_size), dtype=np.uint8)\n",
    "        \n",
    "        # random backgrounfd color\n",
    "        bg_color = np.random.randint(50, 200, 3)\n",
    "        img[:, :] = bg_color\n",
    "        \n",
    "        shape = np.random.choice(self.shapes)\n",
    "        size = np.random.randint(20, 50)\n",
    "        center_x = np.random.randint(size, self.img_size - size)\n",
    "        center_y = np.random.randint(size, self.img_size - size)\n",
    "        \n",
    "        shape_color = np.random.randint(0, 255, 3)\n",
    "        while np.all(np.abs(shape_color - bg_color) < 50):\n",
    "            shape_color = np.random.randint(0, 255, 3)\n",
    "        \n",
    "        if shape == 'circle':\n",
    "            cv2.circle(img, (center_x, center_y), size, \n",
    "                      shape_color.tolist(), -1)\n",
    "            cv2.circle(mask, (center_x, center_y), size, 1, -1)\n",
    "            \n",
    "        elif shape == 'square':\n",
    "            pt1 = (center_x - size, center_y - size)\n",
    "            pt2 = (center_x + size, center_y + size)\n",
    "            cv2.rectangle(img, pt1, pt2, shape_color.tolist(), -1)\n",
    "            cv2.rectangle(mask, pt1, pt2, 1, -1)\n",
    "            \n",
    "        elif shape == 'triangle':\n",
    "            pts = np.array([\n",
    "                [center_x, center_y - size],\n",
    "                [center_x - size, center_y + size],\n",
    "                [center_x + size, center_y + size]\n",
    "            ])\n",
    "            cv2.fillPoly(img, [pts], shape_color.tolist())\n",
    "            cv2.fillPoly(mask, [pts], 1)\n",
    "        \n",
    "        # add some noise\n",
    "        noise = np.random.randint(-20, 20, img.shape, dtype=np.int32)\n",
    "        img = np.clip(img + noise, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        img_tensor = torch.from_numpy(img).permute(2, 0, 1).float() / 255.0\n",
    "        mask_tensor = torch.from_numpy(mask).unsqueeze(0).float()\n",
    "        \n",
    "        return img_tensor, mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "435d9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ShapesDataset(num_samples=200, img_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6385f6d9",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "22f0f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    SAVE_DIR = \"./unet_training_results\"\n",
    "    MODEL_SAVE_PATH = os.path.join(SAVE_DIR, \"best_unet.pth\")\n",
    "    \n",
    "    BATCH_SIZE = 4\n",
    "    NUM_EPOCHS = 10\n",
    "    LEARNING_RATE = 1e-4\n",
    "    IMG_SIZE = 256\n",
    "    NUM_SAMPLES_TRAIN = 1000\n",
    "    NUM_SAMPLES_VAL = 200\n",
    "    \n",
    "    # Dataset params\n",
    "    SHAPES = ['circle', 'square', 'triangle', 'pentagon', 'star']\n",
    "    MIN_SHAPE_SIZE = 30\n",
    "    MAX_SHAPE_SIZE = 70\n",
    "    \n",
    "    # Vizsualization\n",
    "    VISUALIZE_EVERY = 5  # epochs\n",
    "    SAVE_MODEL_EVERY = 10  # epochs\n",
    "\n",
    "os.makedirs(Config.SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8b35cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceBCELoss(nn.Module):    \n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        predictions = torch.sigmoid(predictions)\n",
    "        predictions = predictions.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (predictions * targets).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (\n",
    "            predictions.sum() + targets.sum() + self.smooth)\n",
    "        dice_loss = 1 - dice\n",
    "        \n",
    "        bce_loss = nn.functional.binary_cross_entropy(\n",
    "            predictions, targets, reduction='mean')\n",
    "    \n",
    "        return dice_loss + bce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "791f480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IoULoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        predictions = torch.sigmoid(predictions)\n",
    "        \n",
    "        predictions = predictions.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (predictions * targets).sum()\n",
    "        union = predictions.sum() + targets.sum() - intersection\n",
    "        \n",
    "        iou = (intersection + self.smooth) / (union + self.smooth)\n",
    "        return 1 - iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1121b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions, targets, threshold=0.5):\n",
    "    \"\"\"Вычисление метрик качества\"\"\"\n",
    "    with torch.no_grad():\n",
    "        pred_binary = (torch.sigmoid(predictions) > threshold).float()\n",
    "        targets = targets.float()\n",
    "        \n",
    "        tp = (pred_binary * targets).sum()\n",
    "        fp = (pred_binary * (1 - targets)).sum()\n",
    "        fn = ((1 - pred_binary) * targets).sum()\n",
    "        tn = ((1 - pred_binary) * (1 - targets)).sum()\n",
    "        \n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn + 1e-6)\n",
    "        precision = tp / (tp + fp + 1e-6)\n",
    "        recall = tp / (tp + fn + 1e-6)\n",
    "        f1 = 2 * precision * recall / (precision + recall + 1e-6)\n",
    "        \n",
    "        dice = 2 * tp / (2 * tp + fp + fn + 1e-6)\n",
    "        iou = tp / (tp + fp + fn + 1e-6)\n",
    "        \n",
    "    return {\n",
    "        'accuracy': accuracy.item(),\n",
    "        'precision': precision.item(),\n",
    "        'recall': recall.item(),\n",
    "        'f1': f1.item(),\n",
    "        'dice': dice.item(),\n",
    "        'iou': iou.item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bcfe4cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unet_on_shapes():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    print(\"\\nCreate dataset...\")\n",
    "    train_dataset = ShapesDataset(\n",
    "        num_samples=Config.NUM_SAMPLES_TRAIN,\n",
    "        img_size=Config.IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    val_dataset = ShapesDataset(\n",
    "        num_samples=Config.NUM_SAMPLES_VAL,\n",
    "        img_size=Config.IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=Config.BATCH_SIZE, \n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True if device.type == 'cuda' else False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=Config.BATCH_SIZE, \n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True if device.type == 'cuda' else False\n",
    "    )\n",
    "    \n",
    "    print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "    print(f\"Val dataset size: {len(val_dataset)}\")\n",
    "    print(f\"Batch size: {Config.BATCH_SIZE}\")\n",
    "    print(f\"Train batches: {len(train_loader)}\")\n",
    "    print(f\"Val batches: {len(val_loader)}\")\n",
    "    \n",
    "    print(\"\\nU-Net initializing...\")\n",
    "    model = UNet(n_class=1, in_channels=3)  # binary segmentation\n",
    "    model.to(device)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    criterion = DiceBCELoss()  # or IoULoss() or nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=Config.LEARNING_RATE)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='min', \n",
    "        factor=0.5, \n",
    "        patience=5\n",
    "    )\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    metrics_history = {\n",
    "        'train': {'accuracy': [], 'f1': [], 'dice': [], 'iou': []},\n",
    "        'val': {'accuracy': [], 'f1': [], 'dice': [], 'iou': []}\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Start training!\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for epoch in range(Config.NUM_EPOCHS):\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "        train_metrics = {'accuracy': 0, 'f1': 0, 'dice': 0, 'iou': 0}\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{Config.NUM_EPOCHS} [Train]')\n",
    "        \n",
    "        for batch_idx, (images, masks) in enumerate(train_pbar):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_train_loss += loss.item()\n",
    "            \n",
    "            batch_metrics = calculate_metrics(outputs, masks)\n",
    "            for key in train_metrics.keys():\n",
    "                train_metrics[key] += batch_metrics[key]\n",
    "            \n",
    "            train_pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'lr': f'{optimizer.param_groups[0][\"lr\"]:.2e}'\n",
    "            })\n",
    "        \n",
    "        avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        for key in train_metrics.keys():\n",
    "            train_metrics[key] /= len(train_loader)\n",
    "            metrics_history['train'][key].append(train_metrics[key])\n",
    "        \n",
    "        model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        val_metrics = {'accuracy': 0, 'f1': 0, 'dice': 0, 'iou': 0}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{Config.NUM_EPOCHS} [Val]')\n",
    "            \n",
    "            for images, masks in val_pbar:\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                epoch_val_loss += loss.item()\n",
    "                \n",
    "                batch_metrics = calculate_metrics(outputs, masks)\n",
    "                for key in val_metrics.keys():\n",
    "                    val_metrics[key] += batch_metrics[key]\n",
    "                \n",
    "                val_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        for key in val_metrics.keys():\n",
    "            val_metrics[key] /= len(val_loader)\n",
    "            metrics_history['val'][key].append(val_metrics[key])\n",
    "        \n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "\n",
    "        print(f\"\\Epoch {epoch+1}/{Config.NUM_EPOCHS}:\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "        print(f\"  Train Metrics: Acc={train_metrics['accuracy']:.4f}, \"\n",
    "              f\"F1={train_metrics['f1']:.4f}, Dice={train_metrics['dice']:.4f}\")\n",
    "        print(f\"  Val Metrics:   Acc={val_metrics['accuracy']:.4f}, \"\n",
    "              f\"F1={val_metrics['f1']:.4f}, Dice={val_metrics['dice']:.4f}\")\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': avg_train_loss,\n",
    "                'val_loss': avg_val_loss,\n",
    "                'metrics': val_metrics,\n",
    "            }, Config.MODEL_SAVE_PATH)\n",
    "            print(f\"  Best model saved (Val Loss: {avg_val_loss:.4f})\")\n",
    "\n",
    "        if (epoch + 1) % Config.SAVE_MODEL_EVERY == 0:\n",
    "            checkpoint_path = os.path.join(\n",
    "                Config.SAVE_DIR, f\"checkpoint_epoch_{epoch+1}.pth\"\n",
    "            )\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\"  Checkpoint saved: {checkpoint_path}\")\n",
    "        \n",
    "        if (epoch + 1) % Config.VISUALIZE_EVERY == 0 or epoch == 0:\n",
    "            visualize_results(\n",
    "                model, val_dataset, device, epoch+1,\n",
    "                save_dir=Config.SAVE_DIR,\n",
    "                num_samples=4\n",
    "            )\n",
    "    \n",
    "    history = {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'metrics_history': metrics_history,\n",
    "        'config': vars(Config)\n",
    "    }\n",
    "    \n",
    "    history_path = os.path.join(Config.SAVE_DIR, \"training_history.npy\")\n",
    "    np.save(history_path, history, allow_pickle=True)\n",
    "    \n",
    "    plot_training_history(train_losses, val_losses, metrics_history, Config.SAVE_DIR)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Train finished!\")\n",
    "    print(f\"Best model saved: {Config.MODEL_SAVE_PATH}\")\n",
    "    print(f\"Train history: {history_path}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    return model, history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "15c6916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(model, dataset, device, epoch, save_dir, num_samples=4):\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(16, num_samples*4))\n",
    "    \n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        image, true_mask = dataset[idx]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            input_tensor = image.unsqueeze(0).to(device)\n",
    "            prediction = model(input_tensor)\n",
    "            prediction_prob = torch.sigmoid(prediction).cpu().squeeze()\n",
    "            prediction_binary = (prediction_prob > 0.5).float()\n",
    "        \n",
    "        image_np = image.permute(1, 2, 0).numpy()\n",
    "        true_mask_np = true_mask.squeeze().numpy()\n",
    "        pred_mask_np = prediction_binary.numpy()\n",
    "        \n",
    "        axes[i, 0].imshow(image_np)\n",
    "        axes[i, 0].set_title(\"Image\")\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        axes[i, 1].imshow(true_mask_np, cmap='gray')\n",
    "        axes[i, 1].set_title(\"True mask\")\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        axes[i, 2].imshow(pred_mask_np, cmap='gray')\n",
    "        axes[i, 2].set_title(\"Predicted mask\")\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        im = axes[i, 3].imshow(prediction_prob.numpy(), cmap='hot', vmin=0, vmax=1)\n",
    "        axes[i, 3].set_title(\"Probability map\")\n",
    "        axes[i, 3].axis('off')\n",
    "        plt.colorbar(im, ax=axes[i, 3], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.suptitle(f\"Эпоха {epoch}\", fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    save_path = os.path.join(save_dir, f\"predictions_epoch_{epoch}.png\")\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"  Image saved: {save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8b510af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(train_losses, val_losses, metrics_history, save_dir):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    \n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(epochs, train_losses, 'b-', label='Train Loss', linewidth=2)\n",
    "    axes[0, 0].plot(epochs, val_losses, 'r-', label='Val Loss', linewidth=2)\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].set_title('Training loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 1].plot(epochs, metrics_history['train']['accuracy'], 'b-', \n",
    "                    label='Train Accuracy', linewidth=2)\n",
    "    axes[0, 1].plot(epochs, metrics_history['val']['accuracy'], 'r-', \n",
    "                    label='Val Accuracy', linewidth=2)\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].set_title('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # F1 Score\n",
    "    axes[0, 2].plot(epochs, metrics_history['train']['f1'], 'b-', \n",
    "                    label='Train F1', linewidth=2)\n",
    "    axes[0, 2].plot(epochs, metrics_history['val']['f1'], 'r-', \n",
    "                    label='Val F1', linewidth=2)\n",
    "    axes[0, 2].set_xlabel('Epoch')\n",
    "    axes[0, 2].set_ylabel('F1 Score')\n",
    "    axes[0, 2].set_title('F1 Score')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1, 0].plot(epochs, metrics_history['train']['dice'], 'b-', \n",
    "                    label='Train Dice', linewidth=2)\n",
    "    axes[1, 0].plot(epochs, metrics_history['val']['dice'], 'r-', \n",
    "                    label='Val Dice', linewidth=2)\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Dice Coefficient')\n",
    "    axes[1, 0].set_title('Dice Coefficient')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # IoU\n",
    "    axes[1, 1].plot(epochs, metrics_history['train']['iou'], 'b-', \n",
    "                    label='Train IoU', linewidth=2)\n",
    "    axes[1, 1].plot(epochs, metrics_history['val']['iou'], 'r-', \n",
    "                    label='Val IoU', linewidth=2)\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('IoU')\n",
    "    axes[1, 1].set_title('Intersection over Union (IoU)')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning Rate \n",
    "    axes[1, 2].axis('off')  \n",
    "    \n",
    "    plt.suptitle('U-Net Training history', fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    history_plot_path = os.path.join(save_dir, \"training_history.png\")\n",
    "    plt.savefig(history_plot_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Plots saved: {history_plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9b9637ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_trained_model(model_path, num_test_samples=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = UNet(n_class=1, in_channels=3)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"\\nLoaded model from: {model_path}\")\n",
    "    print(f\"Epoch: {checkpoint['epoch']}\")\n",
    "    print(f\"Val Loss: {checkpoint['val_loss']:.4f}\")\n",
    "    \n",
    "    test_dataset = ShapesDataset(\n",
    "        num_samples=num_test_samples,\n",
    "        img_size=Config.IMG_SIZE,\n",
    "        shapes=Config.SHAPES,\n",
    "        min_size=Config.MIN_SHAPE_SIZE,\n",
    "        max_size=Config.MAX_SHAPE_SIZE\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    total_metrics = {'accuracy': 0, 'f1': 0, 'dice': 0, 'iou': 0}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in test_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            batch_metrics = calculate_metrics(outputs, masks)\n",
    "            \n",
    "            for key in total_metrics.keys():\n",
    "                total_metrics[key] += batch_metrics[key] * images.size(0)\n",
    "    \n",
    "    for key in total_metrics.keys():\n",
    "        total_metrics[key] /= len(test_dataset)\n",
    "    \n",
    "    print(\"\\nTest results:\")\n",
    "    print(f\"Accuracy: {total_metrics['accuracy']:.4f}\")\n",
    "    print(f\"F1 Score: {total_metrics['f1']:.4f}\")\n",
    "    print(f\"Dice Coefficient: {total_metrics['dice']:.4f}\")\n",
    "    print(f\"IoU: {total_metrics['iou']:.4f}\")\n",
    "    \n",
    "    print(\"\\nVisualizing...\")\n",
    "    visualize_results(\n",
    "        model, test_dataset, device, \n",
    "        epoch='test', \n",
    "        save_dir=Config.SAVE_DIR,\n",
    "        num_samples=min(6, num_test_samples)\n",
    "    )\n",
    "    \n",
    "    return total_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b47be85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "\n",
      "Create dataset...\n",
      "Train dataset size: 1000\n",
      "Val dataset size: 200\n",
      "Batch size: 4\n",
      "Train batches: 250\n",
      "Val batches: 50\n",
      "\n",
      "U-Net initializing...\n",
      "Total parameters: 31,043,521\n",
      "Trainable parameters: 31,043,521\n",
      "\n",
      "==================================================\n",
      "Start training!\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 250/250 [13:53<00:00,  3.34s/it, loss=0.7698, lr=1.00e-04]\n",
      "Epoch 1/10 [Val]: 100%|██████████| 50/50 [00:49<00:00,  1.02it/s, loss=2.0700]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Epoch 1/10:\n",
      "  Train Loss: 1.0573 | Val Loss: 2.0273\n",
      "  Train Metrics: Acc=0.9585, F1=0.8320, Dice=0.8320\n",
      "  Val Metrics:   Acc=0.6965, F1=0.3503, Dice=0.3503\n",
      "  Best model saved (Val Loss: 2.0273)\n",
      "  Image saved: ./unet_training_results\\predictions_epoch_1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 250/250 [13:08<00:00,  3.16s/it, loss=0.8251, lr=1.00e-04]\n",
      "Epoch 2/10 [Val]: 100%|██████████| 50/50 [00:53<00:00,  1.07s/it, loss=3.9556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Epoch 2/10:\n",
      "  Train Loss: 0.7931 | Val Loss: 2.0797\n",
      "  Train Metrics: Acc=0.9904, F1=0.9168, Dice=0.9168\n",
      "  Val Metrics:   Acc=0.7429, F1=0.3918, Dice=0.3918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 250/250 [13:23<00:00,  3.22s/it, loss=0.4984, lr=1.00e-04]\n",
      "Epoch 3/10 [Val]: 100%|██████████| 50/50 [00:53<00:00,  1.07s/it, loss=2.7692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Epoch 3/10:\n",
      "  Train Loss: 0.5864 | Val Loss: 2.2671\n",
      "  Train Metrics: Acc=0.9932, F1=0.9424, Dice=0.9424\n",
      "  Val Metrics:   Acc=0.7399, F1=0.3922, Dice=0.3922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 250/250 [13:24<00:00,  3.22s/it, loss=0.2945, lr=1.00e-04]\n",
      "Epoch 4/10 [Val]: 100%|██████████| 50/50 [00:53<00:00,  1.06s/it, loss=0.6472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Epoch 4/10:\n",
      "  Train Loss: 0.4370 | Val Loss: 1.7231\n",
      "  Train Metrics: Acc=0.9936, F1=0.9393, Dice=0.9393\n",
      "  Val Metrics:   Acc=0.8045, F1=0.4904, Dice=0.4904\n",
      "  Best model saved (Val Loss: 1.7231)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 250/250 [13:25<00:00,  3.22s/it, loss=0.1431, lr=1.00e-04]\n",
      "Epoch 5/10 [Val]: 100%|██████████| 50/50 [00:53<00:00,  1.06s/it, loss=4.2105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Epoch 5/10:\n",
      "  Train Loss: 0.2944 | Val Loss: 2.7383\n",
      "  Train Metrics: Acc=0.9950, F1=0.9554, Dice=0.9554\n",
      "  Val Metrics:   Acc=0.6798, F1=0.3749, Dice=0.3749\n",
      "  Image saved: ./unet_training_results\\predictions_epoch_5.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 250/250 [13:08<00:00,  3.15s/it, loss=0.1514, lr=1.00e-04]\n",
      "Epoch 6/10 [Val]: 100%|██████████| 50/50 [00:53<00:00,  1.07s/it, loss=3.3415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Epoch 6/10:\n",
      "  Train Loss: 0.2127 | Val Loss: 3.0233\n",
      "  Train Metrics: Acc=0.9949, F1=0.9585, Dice=0.9585\n",
      "  Val Metrics:   Acc=0.6819, F1=0.3655, Dice=0.3655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|██████████| 250/250 [13:26<00:00,  3.23s/it, loss=0.1332, lr=1.00e-04]\n",
      "Epoch 7/10 [Val]: 100%|██████████| 50/50 [00:53<00:00,  1.07s/it, loss=3.5729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Epoch 7/10:\n",
      "  Train Loss: 0.1459 | Val Loss: 3.1840\n",
      "  Train Metrics: Acc=0.9963, F1=0.9691, Dice=0.9691\n",
      "  Val Metrics:   Acc=0.7229, F1=0.3595, Dice=0.3595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|██████████| 250/250 [13:24<00:00,  3.22s/it, loss=0.4370, lr=1.00e-04]\n",
      "Epoch 8/10 [Val]: 100%|██████████| 50/50 [00:53<00:00,  1.07s/it, loss=0.0968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Epoch 8/10:\n",
      "  Train Loss: 0.1290 | Val Loss: 3.6408\n",
      "  Train Metrics: Acc=0.9957, F1=0.9632, Dice=0.9632\n",
      "  Val Metrics:   Acc=0.5879, F1=0.2671, Dice=0.2671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Train]: 100%|██████████| 250/250 [14:41<00:00,  3.53s/it, loss=0.0365, lr=1.00e-04]\n",
      "Epoch 9/10 [Val]: 100%|██████████| 50/50 [00:45<00:00,  1.09it/s, loss=3.1565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Epoch 9/10:\n",
      "  Train Loss: 0.1020 | Val Loss: 3.3449\n",
      "  Train Metrics: Acc=0.9966, F1=0.9691, Dice=0.9691\n",
      "  Val Metrics:   Acc=0.6782, F1=0.3657, Dice=0.3657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Train]: 100%|██████████| 250/250 [21:19<00:00,  5.12s/it, loss=0.0336, lr=1.00e-04]\n",
      "Epoch 10/10 [Val]: 100%|██████████| 50/50 [01:52<00:00,  2.25s/it, loss=2.7353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Epoch 10/10:\n",
      "  Train Loss: 0.0905 | Val Loss: 4.2428\n",
      "  Train Metrics: Acc=0.9960, F1=0.9671, Dice=0.9671\n",
      "  Val Metrics:   Acc=0.5906, F1=0.2747, Dice=0.2747\n",
      "  Checkpoint saved: ./unet_training_results\\checkpoint_epoch_10.pth\n",
      "  Image saved: ./unet_training_results\\predictions_epoch_10.png\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'mappingproxy' object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trained_model, history = \u001b[43mtrain_unet_on_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 177\u001b[39m, in \u001b[36mtrain_unet_on_shapes\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    169\u001b[39m history = {\n\u001b[32m    170\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtrain_losses\u001b[39m\u001b[33m'\u001b[39m: train_losses,\n\u001b[32m    171\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mval_losses\u001b[39m\u001b[33m'\u001b[39m: val_losses,\n\u001b[32m    172\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmetrics_history\u001b[39m\u001b[33m'\u001b[39m: metrics_history,\n\u001b[32m    173\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mvars\u001b[39m(Config)\n\u001b[32m    174\u001b[39m }\n\u001b[32m    176\u001b[39m history_path = os.path.join(Config.SAVE_DIR, \u001b[33m\"\u001b[39m\u001b[33mtraining_history.npy\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m plot_training_history(train_losses, val_losses, metrics_history, Config.SAVE_DIR)\n\u001b[32m    181\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python_envs\\datascience_env\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:581\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(file, arr, allow_pickle, fix_imports)\u001b[39m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[32m    580\u001b[39m     arr = np.asanyarray(arr)\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m     \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrite_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfix_imports\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfix_imports\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python_envs\\datascience_env\\Lib\\site-packages\\numpy\\lib\\format.py:743\u001b[39m, in \u001b[36mwrite_array\u001b[39m\u001b[34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[39m\n\u001b[32m    741\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pickle_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    742\u001b[39m         pickle_kwargs = {}\n\u001b[32m--> \u001b[39m\u001b[32m743\u001b[39m     \u001b[43mpickle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m array.flags.f_contiguous \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m array.flags.c_contiguous:\n\u001b[32m    745\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n",
      "\u001b[31mTypeError\u001b[39m: cannot pickle 'mappingproxy' object"
     ]
    }
   ],
   "source": [
    "trained_model, history = train_unet_on_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ead88b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
