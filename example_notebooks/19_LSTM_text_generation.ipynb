{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation With LSTM Recurrent Neural\n",
    "http://www.gutenberg.org/cache/epub/11/pg11.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "filename = 'book.txt'\n",
    "file = open(filename, 'r', encoding='utf_8')\n",
    "raw_text = file.read().lower()\n",
    "file.close()\n",
    "raw_text = re.sub(r'[.,\"\\'-?:!;]','', raw_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = {c:i for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158475, 40)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "n_chars, n_vocab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation\n",
    "split the book text up into subsequences with a fixed length of 100 characters, an arbitrary length. \n",
    "\n",
    "split the data by sentences, padding the shorter sequences and truncating the longer ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patterns:  158375\n"
     ]
    }
   ],
   "source": [
    "seq_len = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(n_chars-seq_len):\n",
    "    seq_in = raw_text[i:i+seq_len]\n",
    "    seq_out = raw_text[i+seq_len]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append([char_to_int[seq_out]])\n",
    "n_patterns = len(dataX)\n",
    "print('Number of patterns: ', n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(dataX, (n_patterns, seq_len, 1))\n",
    "X = X / n_vocab\n",
    "y = to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(256, input_shape=(X.shape[1], X.shape[2])),\n",
    "    Dropout(0.7),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1238/1238 [==============================] - 352s 284ms/step - loss: 2.9839\n",
      "Epoch 2/20\n",
      "1238/1238 [==============================] - 341s 276ms/step - loss: 2.8308\n",
      "Epoch 3/20\n",
      "1238/1238 [==============================] - 325s 263ms/step - loss: 2.7602\n",
      "Epoch 4/20\n",
      "1238/1238 [==============================] - 324s 262ms/step - loss: 2.7116\n",
      "Epoch 5/20\n",
      "1238/1238 [==============================] - 324s 262ms/step - loss: 2.6740\n",
      "Epoch 6/20\n",
      "1238/1238 [==============================] - 321s 259ms/step - loss: 2.6410\n",
      "Epoch 7/20\n",
      "1238/1238 [==============================] - 329s 266ms/step - loss: 2.6084\n",
      "Epoch 8/20\n",
      "1238/1238 [==============================] - 325s 262ms/step - loss: 2.5759\n",
      "Epoch 9/20\n",
      "1238/1238 [==============================] - 323s 261ms/step - loss: 2.5423\n",
      "Epoch 10/20\n",
      "1238/1238 [==============================] - 328s 265ms/step - loss: 2.5093\n",
      "Epoch 11/20\n",
      "1238/1238 [==============================] - 326s 263ms/step - loss: 2.4759\n",
      "Epoch 12/20\n",
      "1238/1238 [==============================] - 326s 264ms/step - loss: 2.4437\n",
      "Epoch 13/20\n",
      "1238/1238 [==============================] - 326s 263ms/step - loss: 2.4181\n",
      "Epoch 14/20\n",
      "1238/1238 [==============================] - 326s 263ms/step - loss: 2.3902\n",
      "Epoch 15/20\n",
      "1238/1238 [==============================] - 327s 264ms/step - loss: 2.3650\n",
      "Epoch 16/20\n",
      "1238/1238 [==============================] - 325s 262ms/step - loss: 2.3393\n",
      "Epoch 17/20\n",
      "1238/1238 [==============================] - 328s 265ms/step - loss: 2.3186\n",
      "Epoch 18/20\n",
      "1238/1238 [==============================] - 326s 263ms/step - loss: 2.3000\n",
      "Epoch 19/20\n",
      "1238/1238 [==============================] - 326s 263ms/step - loss: 2.2783\n",
      "Epoch 20/20\n",
      "1238/1238 [==============================] - 327s 264ms/step - loss: 2.2608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fabad350c8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the wored to toen i shink to toen i shink to toen i shink to toen i think to toen i think to toen i think toen the roeee tf the soee a dor oo the soeee the gorse to toen i shink toee in the roeee th the would toen the roeee th the would toen the roeee th the would be an anl the world toene the worl  “ho a toie to toen to toen i shink to toen i shink to toen i shink to toen i think to toen i think toen the roeee tf the soee a dor oo the soeee the gorse to toen i shink toee in the roeee th the would toen the roeee th the would toen the roeee th the would be an anl the world toene the worl  “ho a toie to toen to toen i shink to toen i shink to toen i shink to toen i think to toen i think toen the roeee tf the soee a dor oo the soeee the gorse to toen i shink toee in the roeee th the would toen the roeee th the would toen the roeee th the would be an anl the world toene the worl  “ho a toie to toen to toen i shink to toen i shink to toen i shink to toen i think to toen i think toen the ro"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "int_to_char = {i:c for i, c in enumerate(chars)}\n",
    "\n",
    "start = np.random.randint(len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / n_vocab\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Larger LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(256),\n",
    "    Dropout(0.2),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2475/2475 [==============================] - 1460s 589ms/step - loss: 2.8397\n",
      "Epoch 2/50\n",
      "2475/2475 [==============================] - 1722s 696ms/step - loss: 2.4980\n",
      "Epoch 3/50\n",
      "2475/2475 [==============================] - 1685s 681ms/step - loss: 2.2565\n",
      "Epoch 4/50\n",
      "2475/2475 [==============================] - 1676s 677ms/step - loss: 2.0867\n",
      "Epoch 5/50\n",
      "2475/2475 [==============================] - 1732s 700ms/step - loss: 1.9711\n",
      "Epoch 6/50\n",
      "2475/2475 [==============================] - 1765s 713ms/step - loss: 1.8849\n",
      "Epoch 7/50\n",
      "2475/2475 [==============================] - 1708s 690ms/step - loss: 1.8175\n",
      "Epoch 8/50\n",
      "2475/2475 [==============================] - 1701s 687ms/step - loss: 1.7601\n",
      "Epoch 9/50\n",
      "2475/2475 [==============================] - 1672s 675ms/step - loss: 1.7157\n",
      "Epoch 10/50\n",
      "2475/2475 [==============================] - 1660s 671ms/step - loss: 1.6787\n",
      "Epoch 11/50\n",
      "2475/2475 [==============================] - 1661s 671ms/step - loss: 1.6413\n",
      "Epoch 12/50\n",
      "2475/2475 [==============================] - 1662s 671ms/step - loss: 1.6093\n",
      "Epoch 13/50\n",
      "2475/2475 [==============================] - 1661s 671ms/step - loss: 1.5811\n",
      "Epoch 14/50\n",
      "2475/2475 [==============================] - 1662s 672ms/step - loss: 1.5544\n",
      "Epoch 15/50\n",
      "2475/2475 [==============================] - 1668s 674ms/step - loss: 1.5296\n",
      "Epoch 16/50\n",
      "2475/2475 [==============================] - 1658s 670ms/step - loss: 1.5092\n",
      "Epoch 17/50\n",
      "2475/2475 [==============================] - 1658s 670ms/step - loss: 1.4876\n",
      "Epoch 18/50\n",
      "2475/2475 [==============================] - 1664s 672ms/step - loss: 1.4683\n",
      "Epoch 19/50\n",
      "2475/2475 [==============================] - 1661s 671ms/step - loss: 1.4533\n",
      "Epoch 20/50\n",
      "2475/2475 [==============================] - 1662s 672ms/step - loss: 1.4352\n",
      "Epoch 21/50\n",
      "2475/2475 [==============================] - 1661s 671ms/step - loss: 1.4191\n",
      "Epoch 22/50\n",
      "2475/2475 [==============================] - 1662s 671ms/step - loss: 1.4057\n",
      "Epoch 23/50\n",
      "2475/2475 [==============================] - 1674s 676ms/step - loss: 1.3946\n",
      "Epoch 24/50\n",
      "2475/2475 [==============================] - 1669s 674ms/step - loss: 1.3817\n",
      "Epoch 25/50\n",
      "2475/2475 [==============================] - 1661s 671ms/step - loss: 1.3705\n",
      "Epoch 26/50\n",
      "2475/2475 [==============================] - 1659s 670ms/step - loss: 1.3604\n",
      "Epoch 27/50\n",
      "2475/2475 [==============================] - 1657s 670ms/step - loss: 1.3455\n",
      "Epoch 28/50\n",
      "2475/2475 [==============================] - 1660s 671ms/step - loss: 1.3392\n",
      "Epoch 29/50\n",
      "2475/2475 [==============================] - 1659s 670ms/step - loss: 1.3319\n",
      "Epoch 30/50\n",
      "2475/2475 [==============================] - 1662s 671ms/step - loss: 1.3194\n",
      "Epoch 31/50\n",
      "2475/2475 [==============================] - 1663s 672ms/step - loss: 1.3106\n",
      "Epoch 32/50\n",
      "2475/2475 [==============================] - 1659s 670ms/step - loss: 1.3064\n",
      "Epoch 33/50\n",
      "2475/2475 [==============================] - 1659s 670ms/step - loss: 1.2980\n",
      "Epoch 34/50\n",
      "2475/2475 [==============================] - 1658s 670ms/step - loss: 1.2925\n",
      "Epoch 35/50\n",
      "2475/2475 [==============================] - 1660s 671ms/step - loss: 1.2852\n",
      "Epoch 36/50\n",
      "2475/2475 [==============================] - 1665s 673ms/step - loss: 1.2829\n",
      "Epoch 37/50\n",
      "2475/2475 [==============================] - 1665s 673ms/step - loss: 1.2744\n",
      "Epoch 38/50\n",
      "2475/2475 [==============================] - 1662s 671ms/step - loss: 1.2676\n",
      "Epoch 39/50\n",
      "2475/2475 [==============================] - 1633s 660ms/step - loss: 1.2644\n",
      "Epoch 40/50\n",
      "2475/2475 [==============================] - 1658s 670ms/step - loss: 1.2582\n",
      "Epoch 41/50\n",
      "2475/2475 [==============================] - 1660s 671ms/step - loss: 1.2549\n",
      "Epoch 42/50\n",
      "2475/2475 [==============================] - 1661s 671ms/step - loss: 1.2510\n",
      "Epoch 43/50\n",
      "2475/2475 [==============================] - 1659s 670ms/step - loss: 1.2456\n",
      "Epoch 44/50\n",
      "2475/2475 [==============================] - 1659s 670ms/step - loss: 1.2409\n",
      "Epoch 45/50\n",
      "2475/2475 [==============================] - 1660s 671ms/step - loss: 1.2387\n",
      "Epoch 46/50\n",
      "2475/2475 [==============================] - 1659s 670ms/step - loss: 1.2351\n",
      "Epoch 47/50\n",
      "2475/2475 [==============================] - 1664s 672ms/step - loss: 1.2308\n",
      "Epoch 48/50\n",
      "2475/2475 [==============================] - 1660s 671ms/step - loss: 1.2301\n",
      "Epoch 49/50\n",
      "2475/2475 [==============================] - 1663s 672ms/step - loss: 1.2270\n",
      "Epoch 50/50\n",
      "2475/2475 [==============================] - 1667s 673ms/step - loss: 1.2238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fabe8d4748>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r that”\n",
      "\n",
      "“i won’t think they don’t talk i con’t like the look of the sea and wasn’t the same thing” said the mock turtle “they all move that makes the more the same thing as ‘ou know about the sea the mock turtle i’m a real to go nn thle” said the mock turtle “they all move that makes the more the same thing as ‘ou know about the sea the mock turtle i’m a real to go nn thle” said the mock turtle “they all move that makes the more the same thing as ‘ou know about the sea the mock turtle i’m a real to go nn thle” said the mock turtle “they all move that makes the more the same thing as ‘ou know about the sea the mock turtle i’m a real to go nn thle” said the mock turtle “they all move that makes the more the same thing as ‘ou know about the sea the mock turtle i’m a real to go nn thle” said the mock turtle “they all move that makes the more the same thing as ‘ou know about the sea the mock turtle i’m a real to go nn thle” said the mock turtle “they all move that makes the more the same t"
     ]
    }
   ],
   "source": [
    "start = np.random.randint(len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / n_vocab\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbe58ca63fe33f9eeae9e71d10368d2b4a57f2b1b395836210cc60d362c66949"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
